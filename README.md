# ü§ñ Machine Learning Operations
Projeto da disciplina Projeto de Sistemas Baseados em Aprendizado de M√°quina da UFRN, que consiste em desenvolver o projeto guiado da plataforma do Dataquest, Classifying Disaster-Related Tweets as Real or Fake, aplicando conhecimentos de de boas pr√°ticas de programa√ß√£oe em projetos de aprendizado de m√°quina, como debug, testes, logg, clean code, formata√ß√£o de c√≥digo e desenvolver uma pipeline para execu√ß√£o do projeto utilizando Airflow.

## üìí Projeto
# Airflow Data Pipeline to Download Podcasts
Esse √© projeto se chama <i>Build an Airflow Data Pipeline to Download Podcasts</i> e nele foi constru√≠do um pipeline de dados de quatro etapas usando o Airflow, que √© uma ferramenta popular de engenharia de dados baseada em Python para definir e executar pipelines de dados muito poderosos e flex√≠veis. O pipeline baixar√° epis√≥dios de podcast. Armazenaremos nossos resultados em um banco de dados SQLite que podemos consultar facilmente.. √â um projeto de protif√≥lio dispon√≠vel na plataforma [Dataquest](https://app.dataquest.io/)

## Depend√™ncias
- Airflow 2.7.1
- Python 3.8+
- astroid
- numpy
- pandas
- pylint
- pytest
- pydub
- requests
- sqlite3
- vosk
- xmltodict


## Instru√ß√µes

1. Clone o projeto localmente: 
   ```
   git clone https://github.com/gjmoura/mlops2023.git
   ```
2. Acesse a pasta `Project 02` dentro do diret√≥rio `Python_Essentials_for_MLOps`.
3. Instale as depend√™ncias necess√°rias:
   ```bash
    python --version
    
    CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-2.3.1/constraints-3.9.txt"
    
    pip install "apache-airflow==2.3.1" --constraint "${CONSTRAINT_URL}"
    ```
    ```
    pip install -r requirements.txt
    ```
    
4. Rode airflow server no terminal
    ```
    airflow standalone
    ```
  
5. Cria√ß√£o do banco de dados
    * Rode no terminal `sqlite3 episodes.db`
    * Digite `.databases` no prompt para criar o banco de dados
    * Rode `airflow connections add 'podcasts' --conn-type 'sqlite' --conn-host 'episodes.db'`
    *  `airflow connections get podcasts` para ver informa√ß√µes sobre a conex√£o

6. Execu√ß√£o do c√≥digo via terminal ou utilizando uma IDE:
    * `mkdir episodes` para criar a pasta com os podcasts
    ```
    python podcast_summary.py -t
    ```
    * Voc√™ tamb√©m pode acompanhar o funcionamento na interface do Airflow
7. Para executar os testes rode o comando:
   ```
    pytest 
   ```
8. Para rodar o pylint no c√≥digo rode o comando:
   ```
    pylint podcast_summary.py
   ```


## ‚Ñπ Mais informa√ß√µes
Alunos 
```
Adson Emanuel Santos Amaral
Gustavo Jer√¥nimo Moura de Fran√ßa
Jos√© Augusto Agripino de Oliveira

```
