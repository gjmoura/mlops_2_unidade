# ü§ñ Machine Learning Operations
Projeto da disciplina Projeto de Sistemas Baseados em Aprendizado de M√°quina da UFRN, que consiste em desenvolver o projeto guiado da plataforma do Dataquest, Classifying Disaster-Related Tweets as Real or Fake, aplicando conhecimentos de boas pr√°ticas de programa√ß√£oe em projetos de aprendizado de m√°quina, como debug, testes, logg, clean code, formata√ß√£o de c√≥digo e desenvolver uma pipeline para execu√ß√£o do projeto utilizando Airflow.

## üìí Projeto
# Classifying Disaster-Related Tweets as Real or Fake
Esse √© projeto se chama <i>Classifying Disaster-Related Tweets as Real or Fake</i> e constr√≥i um modelo de classifica√ß√£o de texto de aprendizagem profunda para prever se tweets est√£o relacionados a desastres reais. Utilizando como base o projeto de protif√≥lio dispon√≠vel na plataforma [Dataquest](https://app.dataquest.io/) e um conjunto de dados obtido do Kaggle,o algoritmo passa por etapas que incluem a explora√ß√£o e visualiza√ß√£o dos dados, o pr√©-processamento textual, a segrega√ß√£o dos dados em conjuntos de treino e teste, o treinamento do modelo com TensorFlow e Hugging Face Transformers. Al√©m disso, foi feita uma integra√ß√£o com o Weights and Biases para monitoramento e registro de experimentos. 

## Depend√™ncias
- wandb
- Python 3.8+
- numpy
- pandas
- pytest
- requests
- tensorflow
- seaborn
- transformers
- matplotlib
- scikit-learn
- nltk

Instale as depend√™ncia do projeto:
```
pip install -r requirements.txt
```


## Como executar
Primeiramente, voc√™ precisar√° criar uma conta no [Weight & Biases](https://wandb.ai/site). Em seguida, encontre sua ``API_KEY`` e coloque-a dentro do arquivo ``config.json``.

Garanta que voc√™ tem o python 3.10.x instalado. Ele ser√° necess√°rio para instalar o [airflow 2.7.1](https://airflow.apache.org/docs/apache-airflow/stable/release_notes.html#airflow-2-7-1-2023-09-07), que √© a vers√£o mais recente at√© a data de implementa√ß√£o desta pipeline.

<strong>Para criar um ambiente virtual, siga os passos abaixo.</strong>
Obs.: Os comando a seguir devem ser executados a partir da pasta ``Project_2``.

Criar um ambiente virtual chamado airflow
```
python3.10 -m venv airflow
```

Ativar o ambiente:
```
source ./airflow/bin/activate
```

Para instalar o airflow:
```
AIRFLOW_VERSION=2.7.1
PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"
CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
```

Depois que estiver instalado, voc√™ pode executar a aplica√ß√£o:
```
airflow standalone
```

Ap√≥s isso, ser√° criado automaticamente a pasta ``~/airflow`` e a aplica√ß√£o ficar√° dispon√≠vel na porta ``http://localhost:8080``. No terminal ser√° disponibilizado seu <strong>login e senha</strong>, e √© de extrema import√¢ncia que voc√™ os encontre para que possa entrar na aplica√ß√£o.

Agora ser√° preciso fazer uma autera√ß√£o nas configura√ß√µes do airflow.

Entre na pasta ``dags/`` e obtenha e copie para √°rea de transfer√™ncia o caminho at√© este diret√≥tio:
```
cd dags/
pwd
```

Depois de copiar o caminho da pasta, entre no arquivo de configura√ß√µes do airflow. Para obter o caminho at√© o esse arquivo:
```
find ~/ -name "airflow.cfg"
```

Entre no arquivo com um editor de texto do pr√≥prio terminal:
```
nano {path_of_the_airflow.cfg_file}
```

Edite a vari√°vel ``dags_folder`` para que aponte para a sua pasta dags, cujo caminho voc√™ j√° possui na √°rea de transfer√™ncia. No meu caso ficou assim:
```
dags_folder = /home/augusto/Downloads/mlops2023/dags/tweets_classifying.py
```

Agora, pare a execu√ß√£o do airflow e a execute novamente para aplicar as mudan√ßas feitas:
```
airflow standalone
```

Na p√°gina inicial, em que h√° uma lista com as DAGs, procure pela op√ß√£o "tweets_classifying" e despause essa DAG clicando no toggle ao lado de seu t√≠tulo. Em seguida, clique no t√≠tulo e voc√™ obter√° mais informa√ß√µes sobre ela, como grafos e logs sobre cada task da pipeline. Para executar a pipeline, basta clicar no √≠cone de "play" na parte superior direita.


## Resultados

A partir da execu√ß√£o do c√≥digo foi poss√≠vel obter dentro do Weights & Biases os histogramas e gr√°ficos que foram passados a partir do Logging. As imagens a seguir mostram, repectivamente, os valores para a quantidade de tweets que est√£o relacionados a tweets n√£o reais e reais.

A imagem seguinte mostra os valores para cada target descrito, mas dessa vez eles est√£o normalizados. 

J√° o histograma abaixo real√ßa de forma visual as diferen√ßas entre os targets. 



## ‚Ñπ Mais informa√ß√µes

Alunos:
- Adson Emanuel Santos Amaral
- Gustavo Jer√¥nimo Moura de Fran√ßa
- Jos√© Augusto Agripino de Oliveira
